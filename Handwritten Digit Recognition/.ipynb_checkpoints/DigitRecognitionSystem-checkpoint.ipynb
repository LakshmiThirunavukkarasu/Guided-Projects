{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6d9200d",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fbbdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec88f1f",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a8cf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "dir(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96891ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n",
      "(1797,)\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(digits.images.shape)\n",
    "print(digits.target.shape)\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b2e8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(digits.images[0])\n",
    "plt.show()\n",
    "digits.target_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca91dc",
   "metadata": {},
   "source": [
    "# squeezing the data into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6b88dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_reshaped = digits.images.reshape((len(digits.images), -1))\n",
    "image_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47979db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(image_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235d1875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = digits.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "069cf67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 178]\n",
      " [  1 182]\n",
      " [  2 177]\n",
      " [  3 183]\n",
      " [  4 181]\n",
      " [  5 182]\n",
      " [  6 181]\n",
      " [  7 179]\n",
      " [  8 174]\n",
      " [  9 180]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(digits.target,return_counts = True)\n",
    "result = np.column_stack((unique, counts))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b39bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "print(x_scaled.shape)\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba8513b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d236083",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "362b0f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.96      1.00      0.98        44\n",
      "           2       1.00      1.00      1.00        31\n",
      "           3       1.00      1.00      1.00        36\n",
      "           4       0.97      0.89      0.93        35\n",
      "           5       0.98      0.98      0.98        43\n",
      "           6       1.00      0.94      0.97        35\n",
      "           7       0.98      1.00      0.99        40\n",
      "           8       0.90      0.97      0.93        36\n",
      "           9       0.96      0.93      0.95        28\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "[[32  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 44  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 31  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 31  0  0  0  3  1]\n",
      " [ 0  0  0  0  1 42  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 33  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 35  0]\n",
      " [ 0  0  0  0  0  1  0  1  0 26]]\n",
      "-----------------\n",
      "0.9777777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        45\n",
      "           1       0.91      0.97      0.94        31\n",
      "           2       1.00      1.00      1.00        34\n",
      "           3       1.00      0.97      0.99        40\n",
      "           4       0.97      1.00      0.99        34\n",
      "           5       1.00      1.00      1.00        36\n",
      "           6       1.00      0.98      0.99        42\n",
      "           7       1.00      1.00      1.00        31\n",
      "           8       0.89      0.89      0.89        27\n",
      "           9       1.00      0.95      0.97        40\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.97      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 30  0  0  1  0  0  0  0  0]\n",
      " [ 0  0 34  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 34  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 36  0  0  0  0]\n",
      " [ 1  0  0  0  0  0 41  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 31  0  0]\n",
      " [ 0  3  0  0  0  0  0  0 24  0]\n",
      " [ 0  0  0  0  0  0  0  0  2 38]]\n",
      "-----------------\n",
      "0.9860724233983287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.97      1.00      0.99        38\n",
      "           2       1.00      0.97      0.99        35\n",
      "           3       0.97      0.97      0.97        40\n",
      "           4       1.00      1.00      1.00        31\n",
      "           5       0.98      1.00      0.99        40\n",
      "           6       1.00      1.00      1.00        43\n",
      "           7       1.00      0.97      0.98        32\n",
      "           8       0.97      0.97      0.97        35\n",
      "           9       0.97      0.97      0.97        38\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 34  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 31  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 40  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 43  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 31  0  1]\n",
      " [ 0  0  0  1  0  0  0  0 34  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 37]]\n",
      "-----------------\n",
      "0.9805013927576601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       0.94      0.94      0.94        35\n",
      "           2       0.98      1.00      0.99        43\n",
      "           3       1.00      1.00      1.00        32\n",
      "           4       1.00      0.98      0.99        42\n",
      "           5       1.00      0.94      0.97        31\n",
      "           6       0.97      1.00      0.98        28\n",
      "           7       1.00      1.00      1.00        43\n",
      "           8       0.94      0.94      0.94        36\n",
      "           9       0.97      1.00      0.98        30\n",
      "\n",
      "    accuracy                           0.98       359\n",
      "   macro avg       0.98      0.98      0.98       359\n",
      "weighted avg       0.98      0.98      0.98       359\n",
      "\n",
      "[[39  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 33  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 43  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 32  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 41  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 29  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 28  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 43  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 34  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 30]]\n",
      "-----------------\n",
      "0.9916434540389972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       0.97      1.00      0.99        34\n",
      "           2       1.00      1.00      1.00        34\n",
      "           3       1.00      0.97      0.99        35\n",
      "           4       0.97      0.97      0.97        39\n",
      "           5       0.97      1.00      0.98        32\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.97      0.99        40\n",
      "           9       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "[[35  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 34  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 34  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 38  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 32  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 33  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  0]\n",
      " [ 0  0  0  0  1  0  0  0 39  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 44]]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(300,300), activation='relu', solver='adam', random_state=1, max_iter=2000,shuffle=True,momentum=0.9,alpha=0.001, learning_rate = 'adaptive')\n",
    "acc_score_mlp = []\n",
    "for k, (train_index, test_index) in enumerate(kf.split(x_scaled)):\n",
    "    \n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train, y_test = digits.target[train_index], digits.target[test_index]\n",
    "    \n",
    "    #print(x_train)\n",
    "    #mlp = MLPClassifier(hidden_layer_sizes=(15,), activation='logistic', alpha=1e-4, solver='sgd', tol=1e-4, random_state=1,learning_rate_init=.1, verbose=False)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions = mlp.predict(X_test)\n",
    "    score = accuracy_score(y_test, predictions)\n",
    "    acc_score_mlp.append(score)\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    #print(\"Indices\", np.where(y_test != predictions),\"Expected \", digits.target[np.where(y_test != predictions)], \"Actual\", predictions[np.where(y_test != predictions)])\n",
    "    print(\"-----------------\")\n",
    "    #print(\"[fold {0}] , accurancy: {2:.5f}\".format(k, accuracy_score(y_test, predictions)))\n",
    "    #predictions = mlp.predict(x_test)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d131c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35acd79a",
   "metadata": {},
   "source": [
    "# SVC LInear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4cdae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.96      1.00      0.98        44\n",
      "           2       1.00      1.00      1.00        31\n",
      "           3       1.00      0.97      0.99        36\n",
      "           4       1.00      0.89      0.94        35\n",
      "           5       0.98      1.00      0.99        43\n",
      "           6       1.00      0.97      0.99        35\n",
      "           7       0.98      1.00      0.99        40\n",
      "           8       0.89      0.94      0.92        36\n",
      "           9       0.93      0.93      0.93        28\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.94      1.00      0.97        31\n",
      "           2       0.97      1.00      0.99        34\n",
      "           3       1.00      0.97      0.99        40\n",
      "           4       0.92      1.00      0.96        34\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      0.98      0.99        42\n",
      "           7       1.00      1.00      1.00        31\n",
      "           8       0.92      0.85      0.88        27\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.97       360\n",
      "\n",
      "0.9832869080779945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       1.00      1.00      1.00        38\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.97      0.97      0.97        40\n",
      "           4       1.00      1.00      1.00        31\n",
      "           5       0.95      0.97      0.96        40\n",
      "           6       1.00      1.00      1.00        43\n",
      "           7       1.00      0.97      0.98        32\n",
      "           8       0.94      0.97      0.96        35\n",
      "           9       0.97      0.95      0.96        38\n",
      "\n",
      "    accuracy                           0.98       359\n",
      "   macro avg       0.98      0.98      0.98       359\n",
      "weighted avg       0.98      0.98      0.98       359\n",
      "\n",
      "0.9832869080779945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       0.97      0.94      0.96        35\n",
      "           2       1.00      1.00      1.00        43\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       1.00      1.00      1.00        42\n",
      "           5       0.97      0.97      0.97        31\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        43\n",
      "           8       0.95      0.97      0.96        36\n",
      "           9       0.94      0.97      0.95        30\n",
      "\n",
      "    accuracy                           0.98       359\n",
      "   macro avg       0.98      0.98      0.98       359\n",
      "weighted avg       0.98      0.98      0.98       359\n",
      "\n",
      "0.9860724233983287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       0.92      1.00      0.96        34\n",
      "           2       0.97      1.00      0.99        34\n",
      "           3       0.97      1.00      0.99        35\n",
      "           4       1.00      0.97      0.99        39\n",
      "           5       1.00      1.00      1.00        32\n",
      "           6       1.00      1.00      1.00        33\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        40\n",
      "           9       1.00      0.98      0.99        44\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
    "svc_linear = SVC(kernel='linear')\n",
    "acc_score = []\n",
    "\n",
    "acc_score_svc_linear = []\n",
    "    \n",
    "for k, (train_index, test_index) in enumerate(kf.split(x_scaled)):\n",
    "    \n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train, y_test = digits.target[train_index], digits.target[test_index]\n",
    "    \n",
    "    #print(x_train)\n",
    "    #mlp = MLPClassifier(hidden_layer_sizes=(15,), activation='logistic', alpha=1e-4, solver='sgd', tol=1e-4, random_state=1,learning_rate_init=.1, verbose=False)\n",
    "   \n",
    "    \n",
    "    svc_linear.fit(X_train,y_train)\n",
    "    predictions = svc_linear.predict(X_test)\n",
    "    score = accuracy_score(y_test, predictions)\n",
    "    acc_score_svc_linear.append(score)\n",
    "    print(score)\n",
    "    print(classification_report(y_test,predictions))\n",
    "    #print(\"[fold {0}] , accurancy: {2:.5f}\".format(k, accuracy_score(y_test, predictions)))\n",
    "    #predictions = mlp.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c05cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3868340e",
   "metadata": {},
   "source": [
    "# SVC - RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d419556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9777777777777777\n",
      "0.9832869080779945\n",
      "0.9832869080779945\n",
      "0.9888579387186629\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "acc_score_svc_rbf = []\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(kf.split(x_scaled)):\n",
    "    \n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train, y_test = digits.target[train_index], digits.target[test_index]\n",
    "    \n",
    "    #print(x_train)\n",
    "    #mlp = MLPClassifier(hidden_layer_sizes=(15,), activation='logistic', alpha=1e-4, solver='sgd', tol=1e-4, random_state=1,learning_rate_init=.1, verbose=False)\n",
    "    svc_rbf.fit(X_train,y_train)\n",
    "    predictions = svc_rbf.predict(X_test)\n",
    "    score = accuracy_score(y_test, predictions) \n",
    "    acc_score_svc_rbf.append(score)\n",
    "    print(score)\n",
    "    #print(\"[fold {0}] , accurancy: {2:.5f}\".format(k, accuracy_score(y_test, predictions)))\n",
    "    #predictions = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f81274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SVC(RBF Kernel) model accuracy:  0.981641906530486\n",
      "Total SVC(Linear) model accuracy:  0.9799736923553081\n",
      "Total MLP model accuracy:  0.9816434540389972\n"
     ]
    }
   ],
   "source": [
    "print(\"Total SVC(RBF Kernel) model accuracy: \" , np.mean(acc_score_svc_rbf))  \n",
    "print(\"Total SVC(Linear) model accuracy: \" , np.mean(acc_score_svc_linear))  \n",
    "print(\"Total MLP model accuracy: \" , np.mean(acc_score_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfac07f",
   "metadata": {},
   "source": [
    "# Conclusion: SVC(RBF Kernel) and MLP showed its strength in the cross-validation evaluation with a 98.1% accuracy as compared to SVC(Linear) with 97.9% accurancy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
